# OSWorld Task Delivery Validation Script

This document explains how to prepare an OSWorld Deliverable and how the validation script (`Turing_tooling/validation_script.py`) verifies it.

## Overview

The validator checks a task delivery folder end to end:
- Validates the task JSON against the published schema.
- Confirms the expected directory layout and artefacts exist (and can optionally reshape them with `--rearrange`).
- Parses evaluation artefacts such as `result.txt` and `evaluation_score.txt`, accepting either integers (`0`, `1`) or their float representations (`0.0`, `1.0`).
- Reviews auxiliary assets such as screenshots, accessibility trees, notebooks, and ensures no `args.json` files are present.

## Preparing Your Deliverable

1. Create `Deliverable/<task_id>/` for the task you want to validate.
2. Place the following items inside that directory:
   - `<task_id>.json` ? the OSWorld-compatible config file that includes `model_pass_rate` and `annotator_hints`.
   - `SFT/` containing:
     - `evaluator.diff` with your evaluator implementation changes.
     - `Colab/` with notebooks (if notebooks land inside `Trajectory and Screenshot/` or domain folders such as `<domain>/<task_id>/`, `--rearrange` will relocate them here).
     - `Trajectory and Screenshot/` with matching `.png` screenshots and `.xml` accessibility trees.
     - `libreoffice_writer/<task_id>/evaluation_score.txt`.
   - `claude-4-sonnet-20250514/` containing runs `run_01` ? `run_16` (plain `run_1` style names are acceptable). Each run must provide a `Trajectory and Screenshot/` folder with paired `.png`/`.xml` files and a `result.txt` (either directly inside `Trajectory and Screenshot/` or inside a `<task_id>/` subfolder ? `--rearrange` normalises the location).
   - `Annotator Trajectory/` with `annotator1/`, `annotator2/`, and `annotator3/`. Each annotator directory should include:
     - `Trajectory and Screenshot/` (paired `.png`/`.xml` assets).
     - `Colab/` (if the Colab notebook was captured under the trajectory folder, `--rearrange` moves it beside it).
     - `evaluation_score.txt`.
3. Keep `osworld_updated_schema.json` next to `Deliverable/` (the script looks for it one level up from the task folder).
4. When source material arrives in other layouts (for example `results/pyautogui/a11y_tree/claude-4-sonnet-20250514` or nested `Trajectory and Screenshot/<task_id>/` folders), run the validator with `--rearrange` to relocate everything into the structure above before the checks run.

## Validations Performed

### 1. JSON Structure Validation (`json`)
- Validates `<task_id>.json` against `osworld_updated_schema.json`.
- Fails on schema violations or unreadable JSON.

### 2. Evaluator Diff Check (`evaluator_diff`)
- Collects evaluator functions declared in the schema and compares them with the task JSON.
- If the task references functions outside the schema, verifies that `SFT/evaluator.diff` exists and defines those functions.

### 3. Pass@k Validation (`passk`)
- Ensures the Claude run folder exists and contains exactly 16 run directories.
- Accepts `run_XX` or `run_X` names and auto-creates the canonical layout when `--rearrange` is supplied.
- Reads `result.txt` from each run, whether it lives directly in `Trajectory and Screenshot/` or inside `Trajectory and Screenshot/<task_id>/`.
- Accepts numeric `0`/`1` values (including floats) and fails if every run is identical (average strictly 0 or 1).

### 4. File Structure Check (`structure`)
- Verifies the presence of `<task_id>.json`, `SFT/`, `claude-4-sonnet-20250514/`, and `Annotator Trajectory/`.
- Confirms that `Trajectory and Screenshot/` folders contain both `.png` and `.xml` files, with matching counts, across SFT, Claude runs, and annotators.
- Checks for required `Colab/` directories (and relocates ones nested under a trajectory folder when `--rearrange` is enabled).
- Moves misplaced folders (for example Claude logs under a different root, annotator folders with typos, or nested `<task_id>` wrappers) into their canonical positions when `--rearrange` is used.

### 5. SFT Evaluation Score Check (`sft_score`)
- Locates `evaluation_score.txt` under `SFT/libreoffice_writer/<task_id>/` (falling back to legacy locations when necessary).
- Parses the value as binary (allowing `0`, `1`, `0.0`, or `1.0`) and requires it to be `1`.

### 6. Annotator Scores Check (`annotator_scores`)
- Reads `evaluation_score.txt` for each annotator, accepting integer or float representations of `0`/`1`.
- Requires at least one annotator to pass and one to fail.

### 7. Notebook Assistant Check (`notebook_assistant`)
- Scans every `.ipynb` file beneath the task folder.
- Fails if any cell whose source starts with `**[assistant]` contains the phrase `Executing step`.

### 8. No args.json Check (`no_args`)
- Fails when an `args.json` file is found anywhere inside the task folder.

## Running the Validator

### Command Line Interface

```bash
python Turing_tooling/validation_script.py <delivery_folder> <task_id> [--checks CHECKS] [--rearrange]
```

### Arguments

- `delivery_folder`: Path to the Deliverable folder (e.g., `e:\OSWorld\Deliverable`).
- `task_id`: The task identifier (e.g., `libreoffice-europe-countries-task-1`).
- `--checks`: Optional comma-separated list of checks to run. Defaults to all checks.
- `--rearrange`: Relocates misplaced artefacts (runs, screenshots, notebooks, score files) into the canonical layout before validation.

### Available Checks

- `json`
- `evaluator_diff`
- `passk`
- `structure`
- `sft_score`
- `annotator_scores`
- `notebook_assistant`
- `no_args`

### Examples

1. **Run all validations with auto-rearranging**:
   ```bash
   python Turing_tooling/validation_script.py e:\OSWorld\Deliverable libreoffice-europe-countries-task-1 --rearrange
   ```

2. **Run a subset of checks**:
   ```bash
   python Turing_tooling/validation_script.py e:\OSWorld\Deliverable libreoffice-europe-countries-task-1 --checks json,structure,passk
   ```

3. **Inspect notebook-only issues**:
   ```bash
   python Turing_tooling/validation_script.py e:\OSWorld\Deliverable libreoffice-europe-countries-task-1 --checks notebook_assistant
   ```

## Output Legend

The script uses emojis so you can scan results quickly:

- `?` success
- `?` failure
- `??` item moved while rearranging
- `??` statistics about discovered artefacts
- `??` validation summary
- `??` all selected checks passed
- `??` one or more checks failed
- `??` additional information (e.g., available checks)

Example session:
```
? JSON structure validation: PASSED
? Evaluator diff check: PASSED
?? Structure check: Moved Deliverable/.../Trajectory and Screenshot/libreoffice-europe-countries-task-1 to Deliverable/.../Trajectory and Screenshot.
?? Pass@k validation: Found 16 runs.
? Pass@k validation: PASSED with average 0.75
? File structure check: PASSED
? SFT eval score check: PASSED
?? Annotator scores check: 2 passed (1), 1 failed (0).
? Annotator scores check: PASSED
? Notebook assistant check: PASSED
? No args.json check: PASSED
?? All selected validations PASSED!
?? Validation Summary: 8/8 checks passed.
```

## Exit Codes

- `0`: All requested checks passed.
- `1`: One or more checks failed, or invalid arguments were supplied.

## Requirements

- Python 3.x
- `jsonschema` (`pip install jsonschema`)

## Notes

- The validator expects to find `osworld_updated_schema.json` one directory above the task folder.
- Folder names are treated case-sensitively.
- Use `--rearrange` when adopting assets from ad-hoc capture pipelines; it will move misplaced files but never delete data.



