import argparse
import datetime
import io
import json
import logging
import os
import time
from typing import Any, Dict, Iterable, List, Tuple, TYPE_CHECKING

from PIL import Image

if TYPE_CHECKING:
    from desktop_env.desktop_env import DesktopEnv


LOGGER = logging.getLogger("verify_trajectory")


CONTROL_ACTIONS = {"DONE", "FAIL", "WAIT"}
PY_IMPORT_TEMPLATE = {
    "pyautogui": "import pyautogui",
    "time": "import time",
    "actions": "import desktop_env.actions as actions",
}

_FIX_PYAUTOGUI = None


def ensure_fix_function():
    global _FIX_PYAUTOGUI
    if _FIX_PYAUTOGUI is None:
        from desktop_env.desktop_env import _fix_pyautogui_less_than_bug

        _FIX_PYAUTOGUI = _fix_pyautogui_less_than_bug
    return _FIX_PYAUTOGUI


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Replay a recorded trajectory inside the DesktopEnv and run the evaluator."
    )
    parser.add_argument("--trajectory_file", required=True, help="Path to the trajectory.jsonl file to replay")
    parser.add_argument("--task_config", required=True, help="Path to the task configuration JSON used for the run")
    parser.add_argument(
        "--result_dir",
        default=None,
        help="Directory to store replay artifacts (screenshots, logs, summary). Defaults to a timestamped folder",
    )
    parser.add_argument("--path_to_vm", type=str, default=None, help="Path to the VM file (.vmx or .vbox)")
    parser.add_argument(
        "--provider_name",
        type=str,
        default="virtualbox",
        choices=["virtualbox", "vmware", "docker", "aws", "azure"],
        help="Provider name used by DesktopEnv",
    )
    parser.add_argument("--headless", action="store_true", help="Run the VM in headless mode")
    parser.add_argument("--client_password", type=str, default="", help="Client password for the VM")
    parser.add_argument("--screen_width", type=int, default=1920, help="VM screen width")
    parser.add_argument("--screen_height", type=int, default=1080, help="VM screen height")
    parser.add_argument(
        "--sleep_after_execution",
        type=float,
        default=0.2,
        help="Seconds to pause after each executed action (default: 0.2)",
    )
    parser.add_argument(
        "--max_steps",
        type=int,
        default=1000,
        help="Maximum number of steps to replay before aborting (default: 1000)",
    )
    parser.add_argument(
        "--env_start_retries",
        type=int,
        default=3,
        help="Number of times to retry environment reset if the VM is not ready (default: 3)",
    )
    parser.add_argument(
        "--log_level",
        type=str,
        default="INFO",
        choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
        help="Logging level",
    )
    parser.add_argument(
        "--stop_on_error",
        action="store_true",
        help="Stop immediately if a command execution error is detected (default: continue)",
    )
    return parser.parse_args()


def configure_logging(result_dir: str, level: str) -> None:
    LOGGER.setLevel(getattr(logging, level.upper(), logging.INFO))
    formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")

    stream_handler = logging.StreamHandler()
    stream_handler.setFormatter(formatter)
    LOGGER.addHandler(stream_handler)

    log_path = os.path.join(result_dir, "verification.log")
    file_handler = logging.FileHandler(log_path, encoding="utf-8")
    file_handler.setFormatter(formatter)
    LOGGER.addHandler(file_handler)


def ensure_result_dir(trajectory_path: str, desired_dir: str | None) -> str:
    if desired_dir:
        os.makedirs(desired_dir, exist_ok=True)
        return desired_dir

    base_name = os.path.splitext(os.path.basename(trajectory_path))[0]
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    result_dir = os.path.join("trajectory_verifications", f"{base_name}_{timestamp}")
    os.makedirs(result_dir, exist_ok=True)
    return result_dir


def load_jsonl(path: str) -> List[Dict[str, Any]]:
    steps: List[Dict[str, Any]] = []
    with open(path, "r", encoding="utf-8") as handle:
        for line_number, raw_line in enumerate(handle, start=1):
            line = raw_line.strip()
            if not line:
                continue
            try:
                entry = json.loads(line)
            except json.JSONDecodeError as exc:
                raise ValueError(f"Failed to decode JSON on line {line_number}" ) from exc
            if not isinstance(entry, dict):
                raise ValueError(f"JSON on line {line_number} is not an object: {entry!r}")
            steps.append(entry)
    return steps


def load_task_config(path: str) -> Dict[str, Any]:
    with open(path, "r", encoding="utf-8") as handle:
        return json.load(handle)


def save_screenshot(observation: Dict[str, Any], destination: str) -> bool:
    image_bytes = observation.get("screenshot")
    if not image_bytes:
        return False
    try:
        with Image.open(io.BytesIO(image_bytes)) as screenshot:
            screenshot.save(destination)
        return True
    except Exception as exc:  # pragma: no cover - defensive, should rarely trigger in practice
        LOGGER.warning("Failed to save screenshot to %s: %s", destination, exc)
        return False


def normalise_action(raw_action: Any) -> str | Dict[str, Any]:
    if raw_action is None:
        return ""
    if isinstance(raw_action, (int, float)):
        return str(raw_action)
    if isinstance(raw_action, dict):
        # Some pipelines may store {"command": "..."}
        if "command" in raw_action:
            return raw_action["command"]
        if "action" in raw_action:
            return raw_action["action"]
        return json.dumps(raw_action)
    return str(raw_action)


def requires_import(command: str, token: str) -> bool:
    if token == "pyautogui":
        return "pyautogui." in command and "import pyautogui" not in command
    if token == "time":
        return "time." in command and "import time" not in command
    if token == "actions":
        return "actions." in command and "desktop_env.actions" not in command
    return False


def build_python_command(action_string: str) -> Tuple[str, bool]:
    trimmed = action_string.strip()
    upper_trimmed = trimmed.upper()
    if upper_trimmed in CONTROL_ACTIONS:
        return upper_trimmed, True

    command = trimmed
    if command.startswith("pg."):
        command = command.replace("pg.", "pyautogui.")

    is_python = any(
        command.startswith(prefix)
        for prefix in ("pyautogui.", "time.", "actions.", "import ", "#", "from ")
    ) or "\n" in command

    if not is_python:
        # Treat as literal text to type followed by enter
        typed_literal = json.dumps(command)
        command = f"pyautogui.typewrite({typed_literal})\npyautogui.press('enter')"

    command = ensure_fix_function()(command)

    imports: List[str] = []
    for token, statement in PY_IMPORT_TEMPLATE.items():
        if requires_import(command, token):
            imports.append(statement)

    full_command = "\n".join(imports + [command]) if imports else command
    return full_command, False


def execute_action(
    env: "DesktopEnv",
    action_content: str,
    sleep_after: float,
    stop_on_error: bool,
) -> Tuple[Dict[str, Any], bool, Dict[str, Any]]:
    command, is_control = build_python_command(action_content)

    if is_control:
        LOGGER.debug("Executing control action %s", command)
        observation, _, done, info = env.step(command, pause=sleep_after)
        return observation, done, info

    LOGGER.debug("Executing python command:\n%s", command)
    result = env.controller.execute_python_command(command)
    if isinstance(result, dict) and result.get("error"):
        message = f"VM error while executing command: {result['error']}"
        if stop_on_error:
            raise RuntimeError(message)
        LOGGER.warning(message)

    observation, _, done, info = env.step(None, pause=sleep_after)
    return observation, done, info


def replay_trajectory(
    env: "DesktopEnv",
    steps: Iterable[Dict[str, Any]],
    sleep_after: float,
    stop_on_error: bool,
    result_dir: str,
    max_steps: int,
) -> Tuple[Dict[str, Any], int, bool, Dict[str, Any]]:
    last_observation = env._get_obs()
    save_screenshot(last_observation, os.path.join(result_dir, "step_initial.png"))

    executed_steps = 0
    last_done = False
    last_info: Dict[str, Any] = {}

    for step_index, step in enumerate(steps):
        if step_index >= max_steps:
            LOGGER.warning("Reached --max_steps limit (%d); stopping replay", max_steps)
            break

        action_string = normalise_action(step.get("action"))
        if not action_string:
            LOGGER.debug("Skipping empty action at index %d", step_index)
            continue

        LOGGER.info("Replaying step %d: %s", step_index, action_string)
        last_observation, last_done, last_info = execute_action(
            env=env,
            action_content=action_string,
            sleep_after=sleep_after,
            stop_on_error=stop_on_error,
        )
        executed_steps += 1

        screenshot_name = f"step_{step_index:04d}_after.png"
        save_screenshot(last_observation, os.path.join(result_dir, screenshot_name))

        if last_done:
            LOGGER.info("Environment signalled done after step %d", step_index)
            break

    return last_observation, executed_steps, last_done, last_info


def main() -> None:
    args = parse_args()

    result_dir = ensure_result_dir(args.trajectory_file, args.result_dir)
    configure_logging(result_dir, args.log_level)

    LOGGER.info("Loading task config from %s", args.task_config)
    task_config = load_task_config(args.task_config)

    LOGGER.info("Loading trajectory from %s", args.trajectory_file)
    steps = load_jsonl(args.trajectory_file)
    LOGGER.info("Loaded %d steps", len(steps))

    from desktop_env.desktop_env import DesktopEnv  # import inside to avoid heavy dependency during --help

    env = None
    summary: Dict[str, Any] = {
        "trajectory_file": os.path.abspath(args.trajectory_file),
        "task_config": os.path.abspath(args.task_config),
        "executed_steps": 0,
        "reported_steps": len(steps),
        "done": False,
        "info": {},
        "evaluation_score": None,
    }

    try:
        LOGGER.info("Initializing DesktopEnv")
        env = DesktopEnv(
            path_to_vm=args.path_to_vm,
            action_space="pyautogui",
            provider_name=args.provider_name,
            headless=args.headless,
            screen_size=(args.screen_width, args.screen_height),
            client_password=args.client_password,
            require_a11y_tree=False,
        )

        LOGGER.info("Resetting environment for task")
        reset_errors: List[str] = []
        for attempt in range(1, args.env_start_retries + 1):
            try:
                env.reset(task_config=task_config)
                break
            except ValueError as exc:
                error_message = str(exc)
                reset_errors.append(error_message)
                if "not powered on" in error_message.lower() and attempt < args.env_start_retries:
                    LOGGER.warning(
                        "VMware reported 'not powered on'. Waiting 10s and retrying (%d/%d)",
                        attempt,
                        args.env_start_retries,
                    )
                    time.sleep(10)
                    continue
                raise
        else:
            raise RuntimeError(
                "Environment reset failed after retries. Last errors: " + " | ".join(reset_errors)
            )

        LOGGER.info("Replaying trajectory")
        last_obs, executed_steps, done, info = replay_trajectory(
            env=env,
            steps=steps,
            sleep_after=args.sleep_after_execution,
            stop_on_error=args.stop_on_error,
            result_dir=result_dir,
            max_steps=args.max_steps,
        )
        summary.update({
            "executed_steps": executed_steps,
            "done": done,
            "info": info,
        })

        if not done:
            LOGGER.warning("Trajectory replay finished without DONE/FAIL signal")

        LOGGER.info("Running evaluator")
        score = env.evaluate()
        summary["evaluation_score"] = score
        LOGGER.info("Evaluation score: %s", score)

        score_path = os.path.join(result_dir, "evaluation_score.txt")
        with open(score_path, "w", encoding="utf-8") as handle:
            handle.write(str(score))

    finally:
        if env is not None:
            LOGGER.info("Closing environment")
            env.close()

        summary_path = os.path.join(result_dir, "verification_summary.json")
        with open(summary_path, "w", encoding="utf-8") as handle:
            json.dump(summary, handle, indent=2)
        LOGGER.info("Saved summary to %s", summary_path)


if __name__ == "__main__":
    main()
